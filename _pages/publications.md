---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

## 2024
___

### <span style="color:#52ADC8">Composite Backdoor Attacks Against Large Language Models</span>
<b>Hai Huang</b>, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang.\
In Findings of *2024 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)*.\
[[arXiv](https://arxiv.org/abs/2310.07676)]

## 2023
___

### <span style="color:#52ADC8">Prompt Backdoors in Visual Prompt Learning</span>
<b>Hai Huang</b>, Zhengyu Zhao, Michael Backes, Yun Shen, Yang Zhang.\
Preprint.\
[[arXiv](https://arxiv.org/abs/2310.07632)]

## 2022
___

### <span style="color:#52ADC8">On the Privacy Risks of Cell-Based NAS Architectures</span>
<b>Hai Huang</b>, Zhikun Zhang, Yun Shen, Michael Backes, Qi Li, Yang Zhang.\
In *ACM Conference on Computer and Communications Security (CCS)*, 2022.\
[[PDF](https://dl.acm.org/doi/10.1145/3548606.3560619)] [[arXiv](https://arxiv.org/abs/2209.01688)] [[Code](https://github.com/MiracleHH/nas_privacy)]

## 2021
___

### <span style="color:#52ADC8">Data Poisoning Attacks to Deep Learning Based Recommender Systems</span>
<b>Hai Huang</b>, Jiaming Mu, Neil Zhenqiang Gong, Qi Li, Bin Liu, Mingwei Xu.\
In *ISOC Network and Distributed System Security Symposium (NDSS)*, 2021.\
[[PDF](https://www.ndss-symposium.org/wp-content/uploads/ndss2021_6C-4_24525_paper.pdf)] [[arXiv](https://arxiv.org/abs/2101.02644)] [[Code](https://github.com/MiracleHH/RecommPoison)]